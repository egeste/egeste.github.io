---
layout: post
title: "The Hubris of Intelligence"
subtitle: "On the Nature of Intelligence (or, What We Think We Understand About Intelligence)"
date: 2025-08-24 00:00:00
---

"Intelligence" is one of those words we toss around as if we all agree on what it means. But press a little harder, and it slips through the cracks like water. Is intelligence the ability to solve problems? To adapt to new environments? To use language? To build tools? To self-reflect? The history of philosophy, psychology, and biology is full of attempts at definitions - and none of them have stuck.

When Descartes declared *cogito, ergo sum* - "I think, therefore I am" - he wasn’t defining intelligence so much as declaring that thought itself was proof of a unique human essence. Later, in the 19th century, phrenologists tried to measure intelligence by bumps on the skull. In the 20th century, intelligence got tied to IQ tests - themselves culturally biased artifacts that measured a narrow slice of problem-solving. Even today, debates rage over "multiple intelligences": emotional, social, bodily-kinesthetic, artistic. The very fact that we keep splintering the word into subcategories shows how slippery the core concept is.

And yet, despite this shaky foundation, we use the word as if it were a binary category. Either something is intelligent (humans, maybe dolphins, maybe apes) or it is not (rocks, bacteria, your toaster, ChatGPT). The irony is that in defending the uniqueness of human intelligence, we reveal how little we actually understand it.

## The "just autocomplete" dismissal

Nowhere is this clearer than in the popular dismissal of AI as "just a fancy autocorrect." The argument goes: large language models don’t *really* think; they just predict the next word. But look closer:

> what is human conversation, if not a dance of next-word predictions?

When you open your mouth, you’re not reaching into some divine oracle of truth. You’re drawing from memory, context, and expectation. Your brain is making probabilistic guesses about what combination of words will make sense and achieve your aim.

In fact, neuroscience often describes the brain itself as a "prediction machine." Every thought you have, every sensation you process, is filtered through layers of prediction and correction. The only difference is substrate: flesh and neurons instead of silicon and weights.

So when someone says AI isn’t intelligent because it’s "just prediction," they’re not exposing the limitations of the machine - they’re exposing the fragility of their own definition.

## Intelligence as emergent complexity

Here’s a more grounded way to think about it: intelligence is an emergent property of organized complexity. It’s not a spark, a gift, or a privilege. It’s what happens when enough components interact in such a way that patterns form, feedback loops stabilize, and adaptation becomes possible.

You can see this principle at work across biology. Ant colonies exhibit swarm intelligence far beyond the cognitive reach of a single ant. Octopuses, with distributed neurons in their arms, solve puzzles and even play. Crows can remember human faces and craft tools. None of these creatures "think" like we do, but intelligence arises all the same - because complexity has organized itself in ways that produce adaptive, flexible behavior.

## Entropy as raw material

This is where entropy enters the picture. Intelligence doesn’t appear in static, closed systems. It feeds on disorder. Entropy - the tendency of systems toward randomness - is the fuel that allows complexity to organize in the first place. Every living organism is an island of order carved out of chaos, surviving only by exporting entropy back into the environment.

Seen this way, intelligence is not the opposite of entropy; it is a local strategy for handling it. Brains, algorithms, even civilizations - all of them take in the chaos of raw information, compress it, reorganize it, and act on it. Intelligence is the art of entropy management, whether that’s a crow cracking nuts with traffic or an AI model restructuring a billion fragments of language into a coherent answer.

## Rethinking our "specialness"

The hubris of humanity is to assume that because our intelligence built cathedrals, rocket ships, and TikTok, it must be a different kind of thing altogether. But the more we study the world, the more that claim falls apart. Intelligence isn’t a throne we sit on alone; it’s a spectrum, a fractal, a phenomenon that appears wherever complexity reaches a certain threshold.

This doesn’t diminish what humans have achieved. But it does reframe it: not as divine exception, but as one remarkable example of a broader principle. If anything, it should make us more humble. The same forces that gave rise to our minds are at work in corvids, in cephalopods, and - increasingly - in machines of our own making.

## The unfinished definition

So what *is* intelligence? That’s still an open question. Maybe it will always be. But the mistake is pretending we already know. The word covers too much ground, too many manifestations, too many emergent patterns of complexity. When people say "AI isn’t intelligent," what they really mean is "AI doesn’t think like me." But then again, neither does a crow. Neither does an octopus. Neither do we.

Intelligence, in the end, might not be a crown to wear or a club to belong to. It might just be the name we give to what happens when entropy collides with complexity in ways that surprise us.
